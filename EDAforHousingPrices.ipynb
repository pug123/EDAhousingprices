{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.read_csv(r\"C:\\Users\\Shawlock\\Downloads\\all\\train.csv\")\n",
    "Test_df = pd.read_csv(r\"C:\\Users\\Shawlock\\Downloads\\all\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ID = Train_df['Id']\n",
    "test_ID = Test_df['Id']\n",
    "\n",
    "# Now drop the 'Id' colum since it's unnecessary for the prediction process\n",
    "Train_df.drop(\"Id\", axis = 1, inplace = True)\n",
    "Test_df.drop(\"Id\", axis = 1, inplace = True)\n",
    "Train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=Train_df[\"GrLivArea\"], y= Train_df[\"SalePrice\"])\n",
    "plt.xlabel(\"GrLivArea\", fontsize = 13)\n",
    "\n",
    "plt.ylabel(\"SalePrice\", fontsize = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = Train_df.drop(Train_df[(Train_df[\"GrLivArea\"]>4000) & (Train_df[\"SalePrice\"]<300000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=Train_df[\"GrLivArea\"], y= Train_df[\"SalePrice\"])\n",
    "plt.xlabel(\"GrLivArea\", fontsize = 13)\n",
    "\n",
    "plt.ylabel(\"SalePrice\", fontsize = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will check our target variable for the skewness\n",
    "(mu, sigma) = norm.fit(Train_df['SalePrice'])\n",
    "\n",
    "# 1. Plot Sale Price\n",
    "sns.distplot(Train_df['SalePrice'] , fit=norm);\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot SalePrice as a QQPlot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(Train_df['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try the log tranformation to make it normal\n",
    "Train_df[\"SalePrice\"] = np.log1p(Train_df[\"SalePrice\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plot Sale Price\n",
    "sns.distplot(Train_df['SalePrice'] , fit=norm);\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(Train_df['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot SalePrice as a QQPlot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(Train_df['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving train & test shapes\n",
    "ntrain = Train_df.shape[0]\n",
    "ntest = Test_df.shape[0]\n",
    "\n",
    "# Creating y_train variable\n",
    "y_train = Train_df.SalePrice.values\n",
    "Dataset = pd.concat((Train_df, Test_df)).reset_index(drop=True)\n",
    "Dataset.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"Dataset size is : {}\".format(Dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the further processing, let's separate numeric and categorical data\n",
    "numeric_data = Train_df.select_dtypes(include = [np.number])\n",
    "categoric_data = Train_df.select_dtypes(exclude=[np.number])\n",
    "print(\"there are {} numeric and {} categoric features in the dataset\".format(numeric_data.shape[1], categoric_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corelation for the numeric data\n",
    "corr = numeric_data.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlarged heatmap with correlations\n",
    "k=10\n",
    "cols = corr.nlargest(k, \"SalePrice\")[\"SalePrice\"].index\n",
    "cm = np.corrcoef(Train_df[cols].values.T)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr[\"SalePrice\"].sort_values(ascending=False)[:15],'\\n')#top 15 values\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(corr[\"SalePrice\"].sort_values(ascending=False)[-5:])#last 15 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df[\"LotShape\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check the mean price per quality and plot it\n",
    "pivot = Train_df.pivot_table(index=\"OverallQual\" , values= \"SalePrice\", aggfunc=np.median)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot(kind=\"bar\", color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "categoric_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2 = Train_df.pivot_table(index=\"GarageType\" , values= \"SalePrice\", aggfunc=np.median)\n",
    "pivot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot2.plot(kind=\"bar\", color='violet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = (Dataset.isnull().sum() / len(Dataset)) * 100 #Total missing values in the dataset\n",
    "all_data = all_data.drop(all_data[all_data == 0].index).sort_values(ascending=False)[:30] #Excluding values with \"0\" as an entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percent missing data\n",
    "f, ax= plt.subplots(figsize=(15,12))\n",
    "plt.xticks(rotation=\"90\")\n",
    "sns.barplot(x=all_data.index, y=all_data)\n",
    "plt.xlabel(\"Features\", fontsize=15)\n",
    "plt.ylabel(\"Percent of missing value\", fontsize=15)\n",
    "plt.title(\"Percent missing data by featue\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"PoolQC\"] = Dataset[\"PoolQC\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"MiscFeature\"] = Dataset[\"MiscFeature\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"Alley\"] = Dataset[\"Alley\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"Fence\"] = Dataset[\"Fence\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"FireplaceQu\"] = Dataset[\"FireplaceQu\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"LotFrontage\"] = Dataset.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"GarageFinish\", \"GarageQual\", \"GarageCond\", \"GarageType\"]:\n",
    "    Dataset[col] = Dataset[col].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    Dataset[col] = Dataset[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    Dataset[col] = Dataset[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    Dataset[col] = Dataset[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"MasVnrType\"] = Dataset[\"MasVnrType\"].fillna(\"None\")\n",
    "Dataset[\"MasVnrArea\"] = Dataset[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['MSZoning'] = Dataset['MSZoning'].fillna(Dataset['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"Functional\"] = Dataset[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Electrical'] = Dataset['Electrical'].fillna(Dataset['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['KitchenQual'] = Dataset['KitchenQual'].fillna(Dataset['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Exterior1st'] = Dataset['Exterior1st'].fillna(Dataset['Exterior1st'].mode()[0])\n",
    "Dataset['Exterior2nd'] = Dataset['Exterior2nd'].fillna(Dataset['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['SaleType'] = Dataset['SaleType'].fillna(Dataset['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['MSSubClass'] = Dataset['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check remaining missing values if any \n",
    "all_data_na = (Dataset.isnull().sum() / len(Dataset)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting those variables which should be categorical, rather than numeric\n",
    "for col in ('MSSubClass', 'OverallCond', 'YrSold', 'MoSold'):\n",
    "    Dataset[col] = Dataset[col].astype(str)\n",
    "    \n",
    "Dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(Dataset[c].values)) \n",
    "    Dataset[c] = lbl.transform(list(Dataset[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(Dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total sqfootage feature as new feature\n",
    "Dataset['TotalSF'] = Dataset['TotalBsmtSF'] + Dataset['1stFlrSF'] + Dataset['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "# Applying a log(1+x) transformation to all skewed numeric features\n",
    "numeric_feats = Dataset.dtypes[Dataset.dtypes != \"object\"].index\n",
    "\n",
    "# Compute skewness\n",
    "skewed_feats = Dataset[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on number of skewed features above 75% threshold\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"Total number of features requiring a fix for skewness is: {}\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feature in skewed_features:\n",
    "    Dataset[feature] = boxcox1p(Dataset[feature], lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.get_dummies(Dataset)\n",
    "print(Dataset.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
